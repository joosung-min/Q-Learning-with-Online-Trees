{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599089124293",
   "display_name": "Python 3.7.8 64-bit ('torch': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 3 competible version for 'On-line Random Forest' (Saffari 2009)\n",
    "## Original Python 2 code by Arthur Lui (https://github.com/luiarthur/ORFpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On-line Random Forest\n",
    "---\n",
    "\n",
    "Sequential training example <x, y>\n",
    "\n",
    "The size of the forest: T\n",
    "\n",
    "The minimum number of samples: $\\alpha$\n",
    "\n",
    "The minimum gain: $\\beta$\n",
    "\n",
    "---\n",
    "\n",
    "**For** t in 1 to T:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; k $\\leftarrow$ Poisson($\\lambda$) // $\\lambda$ = 1 in the paper\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; **If** k > 0:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **For** _ in 1 to k:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; j = findLeaf(x) // j-th node\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // updateNode(j, <x, y>):\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **If** $|R_{j}| > \\alpha$ and $\\vartriangle L(R_{j}, s) > \\beta$:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Find the best test:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $s_{j} = argmax_{s \\in S} \\vartriangle(R_{j}, s)$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $createLeftChild(p_{jls})$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $createRightChild(p_{jrs})$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **end if**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **end for**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; **else** # If k = 0\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Estimate OOBE_{t} $\\leftarrow$ updateOOBE(<x, y>)\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; **end if**\n",
    "\n",
    "**end for**\n",
    "\n",
    "// Temporal Knowledge Weighting\n",
    "\n",
    "Select a tree randomly from {$f_{t} | f_{t} \\in F, age_{t} > 1/ \\gamma$}\n",
    "\n",
    "**If** OOBE_{t} > rand():\n",
    "// In regression, standardize OOBE \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; // Discard the tree.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $f_{t} = newTree()$\n",
    "\n",
    "**end if**\n",
    "\n",
    "\n",
    "Output the forest F\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified version would have:\n",
    "\n",
    "* Multi-output for regression - not done. Possible options:\n",
    "\n",
    "    * Read and apply 'Multivariate Random Forest'(Segal 2011)\n",
    "    \n",
    "    * Split data into n_actions and grow independent forest for each action\n",
    "    \n",
    "    * Limit the number of leaf nodes to be n_actions by setting maxDepth= n_actions/2,\n",
    "    and obtain the mean action values at each leaf node. (X)\n",
    "\n",
    "* Temporal Knowledge Weighting - Done. But this seems to reduce (classification) accuracy?\n",
    "\n",
    "* Multi-core operation for tree construction - not done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changes**\n",
    "\n",
    "* 2020-08-17:\n",
    "    * Added temporal knowledge weighting in ORF class\n",
    "\n",
    "* 2020-08-16: \n",
    "    * Replaced map(lambda x: ...) with list(map(lambda x: ...))\n",
    "    * Replaced 'xrange' with 'range'\n",
    "    * Replaced '.has_key()' with 'if _ in .keys()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import unittest\n",
    "from tqdm import tqdm\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataRange(X):\n",
    "    \"\"\"\n",
    "    Accepts a list of lists (X) and returns the \"column\" ranges. e.g.\n",
    "    \n",
    "    X = [[8,7,3], \n",
    "         [4,1,9],\n",
    "         [5,6,2]]\n",
    "    dataRange(X) # returns: [ [4,8], [1,7], [2,9] ]\n",
    "    \"\"\"\n",
    "    def col(j):\n",
    "        return list(map(lambda x: x[j], X))\n",
    "\n",
    "    k = len(X[0]) # number of columns in X\n",
    "    return list(map(lambda j: [ min(col(j)), max(col(j)) ], range(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree: # Node object\n",
    "    \"\"\"\n",
    "    # Tree - Binary tree class\n",
    "\n",
    "    Example:\n",
    "        from tree import Tree\n",
    "\n",
    "        t1 = Tree(1)\n",
    "        t1.draw()\n",
    "        t2 = Tree(1,Tree(2),Tree(3))\n",
    "        t3 = Tree(1,t2,Tree(4))\n",
    "        t4 = Tree(1,t2,t3)\n",
    "        t4.draw()\n",
    "\n",
    "        t4.maxDepth()  # should be 4\n",
    "        t4.size()      # should be 9\n",
    "        t4.numLeaves() # should be 5\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, elem, left=None, right=None):\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        t1 = Tree(1)                # creates a tree with a root node (1) and no children\n",
    "        t2 = Tree(1,Tree(2),Tree(3) # creates a tree with a root node (1) with left tree (2) and right tree(3)\n",
    "        t3 = Tree(1,t2,Tree(4))     # creates a tree with a root node (1) with left subtree (t2) and right tree(4)\n",
    "\n",
    "        =====================================================\n",
    "        Note: Nodes in tree must have exactly 2 or 0 children\n",
    "        =====================================================\n",
    "        \"\"\"\n",
    "        assert((left == None and right == None) or (left != None and right != None))\n",
    "        self.elem = elem\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def updateChildren(self,l,r):\n",
    "        \"\"\"\n",
    "        updates the left and right children trees.  e.g.\n",
    "\n",
    "        >>> t = Tree(1)\n",
    "        >>> t.draw()\n",
    "\n",
    "        Leaf(1)\n",
    "\n",
    "        >>> t.updateChildren(Tree(2),Tree(3))\n",
    "        \n",
    "        __1__\n",
    "        2   3\n",
    "        \"\"\"\n",
    "        self.left, self.right = l,r\n",
    "\n",
    "    def isLeaf(self):\n",
    "        \"\"\"\n",
    "        returns a boolean. True if the Tree has no children, False otherwise\n",
    "        \"\"\"\n",
    "        return self.left == None and self.right == None\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"\n",
    "        returns the number of internal nodes in tree\n",
    "        \"\"\"\n",
    "        return 1 if self.isLeaf() else self.left.size() + self.right.size() + 1\n",
    "    \n",
    "    def numLeaves(self):\n",
    "        \"\"\"\n",
    "        returns number of leaves in tree\n",
    "        \"\"\"\n",
    "        return  1 if self.isLeaf() else self.left.numLeaves() + self.right.numLeaves()\n",
    "\n",
    "    def maxDepth(self):\n",
    "        \"\"\"\n",
    "        returns maximum depth of tree\n",
    "        \"\"\"\n",
    "        return self.__md(1)\n",
    "\n",
    "    def __md(self,s):\n",
    "        return s if self.isLeaf() else max(self.left.__md(s+1),self.right.__md(s+1))\n",
    "\n",
    "    def inOrder(self):\n",
    "        \"\"\"\n",
    "        Returns the in-order sequence of tree. Needs to be implemented...\n",
    "        \"\"\"\n",
    "        print(\"return in-order sequence of tree. needs to be implemented\") # FIXME\n",
    "        pass\n",
    "\n",
    "    def preOrder(self):\n",
    "        \"\"\"\n",
    "        Returns the pre-order sequence of tree. Needs to be implemented...\n",
    "        \"\"\"\n",
    "        print(\"return pre-order sequence of tree. needs to be implemented\") # FIXME\n",
    "        pass\n",
    "\n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Draw the tree in a pretty way in the console. Good for smaller trees. You probably don't want to draw a very large tree...\n",
    "        \"\"\"\n",
    "        print(self.treeString())\n",
    "\n",
    "    def treeString(self,fun=False):\n",
    "        \"\"\"\n",
    "        Returns a string representing the flattened tree\n",
    "        \"\"\"\n",
    "        if fun:\n",
    "            return \"Leaf(\" + self.elem.toString() + \")\" if self.isLeaf() else \"\\n\" + \"\\n\".join( self.__pretty(spacing=1,fun=fun) ) + \"\\n\"\n",
    "        else:\n",
    "            return \"Leaf(\" + str(self.elem) + \")\" if self.isLeaf() else \"\\n\" + \"\\n\".join( self.__pretty(spacing=1,fun=fun) ) + \"\\n\"\n",
    "\n",
    "    def __pretty(self,spacing=3,fun=False):\n",
    "        def paste(l, r): # l,r: string lists\n",
    "            def elongate(ls):\n",
    "                maxCol = np.max(list(map(len,ls)))\n",
    "                return list(map(lambda  s: s + \" \"*(maxCol - len(s)) , ls))\n",
    "\n",
    "            maxRow = np.max(list(map(len, [l,r]) ))\n",
    "            tmp = list(map(lambda x: x + [\"\"]*(maxRow-len(x)), [l,r]))\n",
    "            # newL,newR = map(elongate,tmp)\n",
    "            newL, newR = elongate(tmp)\n",
    "            return [newL[i] + newR[i] for i in range(maxRow)]\n",
    "\n",
    "        ps = self.elem.toString() if fun else str(self.elem)\n",
    "        ls,rs = list(map(lambda x: [x.elem.toString() if fun else str(x.elem)] if x.isLeaf() else x.__pretty(spacing,fun), (self.left,self.right)))\n",
    "        posL = ls[0].index(self.left.elem.toString() if fun else str(self.left.elem))\n",
    "        posR = rs[0].index(self.right.elem.toString() if fun else str(self.right.elem))\n",
    "        top = \" \"*posL + \"_\"*(spacing+len(ls[0])-posL) + ps + \"_\"*(spacing+posR) + \" \"*(len(rs[0])-posR)\n",
    "        bottom = paste(ls, paste([\" \"*(spacing+len(ps))],rs)) # use reduce?\n",
    "        return [top] + bottom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORT: # Tree object\n",
    "    \"\"\"\n",
    "    constructor for Online Random Forest (ORT)\n",
    "    The theory for ORT was developed by Amir Saffari. see http://lrs.icg.tugraz.at/pubs/saffari_olcv_09.pdf\n",
    "\n",
    "    Only one parameter in constructor: param\n",
    "    param is a dictionary having at least the following entries:\n",
    "\n",
    "    - minSamples       : minimum number of samples a node has to see before splitting\n",
    "    - minGain          : minimum reduction in node impurity (classification or sd of node) required for splitting\n",
    "    - xrng             : range of the input space (see utils.dataRange)\n",
    "\n",
    "    Also for classification, you must set numClasses:\n",
    "    - numClasses       : number of classes in response (it is assumed that the responses are integers 0,...,n-1)\n",
    "\n",
    "    The following are optional parameters with defaults:\n",
    "    - numClasses       : see above (default: 0, for regression)\n",
    "    - numTests         : Number of potential split location and dimension pairs to test (defaul: 10)\n",
    "    - maxDepth         : Maximum depth a tree is allowed to have. A tree stops growing branches that have depth = maxDepth (default: 30. NOTE THAT YOUR TREE WILL NOT GROW BEYOND 30 DEEP, SET maxDepth TO BE A VALUE GREATER THAN 30 IF YOU WANT LARGER TREES!!!)\n",
    "    - gamma            : Trees that are of age 1/gamma may be discarded. see paper (default: 0, for no discarding of old trees). Currently not implemented.\n",
    "\n",
    "\n",
    "    Examples:\n",
    "        xrng = [[x0_min,x0_max], [x1_min,x1_max], [x2_min,x2_max]]\n",
    "        param = {'minSamples': 5, 'minGain': .1, 'numClasses': 10, 'xrng': xrng}\n",
    "        ort = ORT(param)\n",
    "    \"\"\"\n",
    "    def __init__(self,param):\n",
    "        self.param = param\n",
    "        self.age = 0\n",
    "        self.minSamples = param['minSamples']\n",
    "        self.minGain = param['minGain']\n",
    "        self.xrng = param['xrng']\n",
    "        self.gamma = param['gamma'] if 'gamma' in param.keys() else 0\n",
    "        self.numTests = param['numTests'] if 'numTests' in param.keys() else 10\n",
    "        self.numClasses = param['numClasses'] if 'numClasses' in param.keys() else 0\n",
    "        self.maxDepth = param['maxDepth'] if 'maxDepth' in param.keys() else 30 # This needs to be implemented to restrain the maxDepth of the tree. FIXME\n",
    "        self.tree = Tree( Elem(param=param) )\n",
    "        self.OOBError = 0\n",
    "        self.error_sum = 0\n",
    "        self.error_n = 0\n",
    "\n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        draw a pretty online random tree. Usage:\n",
    "\n",
    "        ort.draw()\n",
    "        \"\"\"\n",
    "        print(self.tree.treeString(fun=True))\n",
    "\n",
    "    def update(self,x,y):\n",
    "        \"\"\"\n",
    "        updates the ORT\n",
    "\n",
    "        - x : list of k covariates (k x 1)\n",
    "        - y : response (scalar)\n",
    "\n",
    "        usage: \n",
    "\n",
    "        ort.update(x,y)\n",
    "        \"\"\"\n",
    "        k = self.__poisson(1) # draw a random poisson\n",
    "        if k == 0:\n",
    "            self.OOBError = self.__updateOOBE(x,y)\n",
    "        else:\n",
    "            for _ in range(k):\n",
    "                self.age += 1\n",
    "                (j,depth) = self.__findLeaf(x,self.tree)\n",
    "                j.elem.update(x,y)\n",
    "                #if j.elem.numSamplesSeen > self.minSamples and depth < self.maxDepth: # FIXME: which is the correct approach?\n",
    "                if j.elem.stats.n > self.minSamples and depth < self.maxDepth:\n",
    "                    g = self.__gains(j.elem)\n",
    "                    if any([ gg >= self.minGain for gg in g ]):\n",
    "                        bestTest = j.elem.tests[np.argmax(g)]\n",
    "                        j.elem.updateSplit(bestTest.dim,bestTest.loc)\n",
    "                        j.updateChildren( Tree(Elem(self.param)), Tree(Elem(self.param)) )\n",
    "                        j.left.elem.stats = bestTest.statsL\n",
    "                        j.right.elem.stats = bestTest.statsR\n",
    "                        j.elem.reset()\n",
    "\n",
    "    def predict(self,x):\n",
    "        \"\"\"\n",
    "        returns a scalar prediction based on input (x)\n",
    "\n",
    "        - x : list of k covariates (k x 1)\n",
    "        \n",
    "        usage: \n",
    "        \n",
    "        ort.predict(x)\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.__findLeaf(x,self.tree)[0].elem.pred() # [0] returns the node, [1] returns the depth\n",
    "\n",
    "    def __gains(self,elem):\n",
    "        tests = elem.tests\n",
    "        def gain(test):\n",
    "            statsL, statsR = test.statsL,test.statsR\n",
    "            nL,nR = statsL.n,statsR.n\n",
    "            n = nL + nR + 1E-9\n",
    "            lossL = 0 if nL==0 else statsL.impurity()\n",
    "            lossR = 0 if nR==0 else statsR.impurity()\n",
    "            g = elem.stats.impurity() - (nL/n) * lossL - (nR/n)  * lossR\n",
    "            return 0 if g < 0 else g\n",
    "        return map(gain, tests)\n",
    "\n",
    "    def __findLeaf(self, x, tree, depth=0):\n",
    "        if tree.isLeaf(): \n",
    "            return (tree,depth)\n",
    "        else:\n",
    "            (dim,loc) = tree.elem.split()\n",
    "            if x[dim] < loc:\n",
    "                return self.__findLeaf(x,tree.left,depth+1)\n",
    "            else:\n",
    "                return self.__findLeaf(x,tree.right,depth+1)\n",
    "\n",
    "    def __poisson(self,lam=1): # fix lamda = 1\n",
    "      l = np.exp(-lam)\n",
    "      def loop(k,p):\n",
    "          return loop(k+1, p * random.random()) if (p > l) else k - 1\n",
    "      return loop(0,1)\n",
    "\n",
    "    def __updateOOBE(self,x,y):\n",
    "        self.error_sum += (y - self.predict(x))**2\n",
    "        self.error_n += 1\n",
    "        OOBError = np.sqrt(self.error_sum)/self.error_n\n",
    "\n",
    "        return OOBError\n",
    "\n",
    "class SuffStats:\n",
    "    def __init__(self,numClasses=0,sm=0.0,ss=0.0):\n",
    "        self.n = 0\n",
    "        self.__classify = numClasses > 0\n",
    "        self.eps = 1E-10\n",
    "        if numClasses > 0:\n",
    "            self.counts = [0] * numClasses\n",
    "        else:\n",
    "            self.sum = sm\n",
    "            self.ss = ss\n",
    "\n",
    "    def update(self,y):\n",
    "        self.n += 1\n",
    "        if self.__classify:\n",
    "            self.counts[y] += 1\n",
    "        else:\n",
    "            self.sum += y\n",
    "            self.ss += y*y\n",
    "\n",
    "    def reset(self):\n",
    "        self.n = None\n",
    "        self.eps = None\n",
    "        self.__classify = None\n",
    "        if self.__classify:\n",
    "            self.counts = None\n",
    "        else:\n",
    "            self.sum = None\n",
    "            self.ss = None\n",
    "\n",
    "    def pred(self): # gives predictions\n",
    "        if self.__classify:\n",
    "            return np.argmax(self.counts)\n",
    "        else:\n",
    "            return self.sum / (self.n+self.eps)\n",
    "    \n",
    "    def impurity(self):\n",
    "        n = self.n + self.eps\n",
    "        if self.__classify:\n",
    "            return np.sum(list(map(lambda x: -x/n * np.log2(x/n + self.eps), self.counts))) # entropy\n",
    "        else:\n",
    "            prd = self.pred()\n",
    "            return np.sqrt( self.ss/n - prd*prd ) # sd of node\n",
    "\n",
    "class Test:\n",
    "    def __init__(self,dim,loc,numClasses):\n",
    "        self.__classify = numClasses > 0\n",
    "        self.statsL = SuffStats(numClasses=numClasses)\n",
    "        self.statsR = SuffStats(numClasses=numClasses)\n",
    "        self.dim = dim\n",
    "        self.loc = loc\n",
    "\n",
    "    def update(self,x,y):\n",
    "        if x[self.dim] < self.loc:\n",
    "            self.statsL.update(y) \n",
    "        else:\n",
    "            self.statsR.update(y)\n",
    "\n",
    "class Elem: #HERE\n",
    "    def __init__(self,param,splitDim=-1,splitLoc=0,numSamplesSeen=0):\n",
    "        self.xrng = param['xrng']\n",
    "        self.xdim = len(param['xrng'])\n",
    "        self.numClasses = param['numClasses'] if 'numClasses' in param.keys() else 0\n",
    "        self.numTests = param['numTests'] if 'numTests' in param.keys() else 10\n",
    "        self.splitDim = splitDim\n",
    "        self.splitLoc = splitLoc\n",
    "        self.numSamplesSeen = numSamplesSeen\n",
    "        self.stats = SuffStats(self.numClasses)\n",
    "        self.tests = [ self.generateTest() for _ in range(self.numTests) ]\n",
    "\n",
    "    def reset(self):\n",
    "        self.stats = None #self.stats.reset()\n",
    "        self.tests = None\n",
    "\n",
    "    def generateTest(self):\n",
    "        dim = random.randrange(self.xdim)\n",
    "        loc = random.uniform(self.xrng[dim][0],self.xrng[dim][1])\n",
    "        return Test(dim, loc, self.numClasses)\n",
    "\n",
    "    def toString(self):\n",
    "        return str(self.pred()) if self.splitDim == -1 else \"X\" + str(self.splitDim+1) + \" < \" + str(round(self.splitLoc,2))\n",
    "\n",
    "    def pred(self): # gives the predicted value\n",
    "        return self.stats.pred()\n",
    "    \n",
    "    def update(self,x,y):\n",
    "        self.stats.update(y)\n",
    "        self.numSamplesSeen += 1\n",
    "        for test in self.tests:\n",
    "            test.update(x,y)\n",
    "\n",
    "    def updateSplit(self,dim,loc):\n",
    "        self.splitDim, self.splitLoc = dim, loc\n",
    "\n",
    "    def split(self):\n",
    "        return (self.splitDim,self.splitLoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORF:\n",
    "    def __init__(self,param,numTrees=100,ncores=0):\n",
    "        \"\"\"\n",
    "        Constructor for Online Random Forest. For more info: >>> help(ORT)\n",
    "\n",
    "        One variable (param) is required to construct an ORF:\n",
    "        - param          : same as that in ORT. see >>> help(ORT)\n",
    "        param is a dictionary having at least the following entries:\n",
    "\n",
    "            - minSamples : minimum number of samples a node has to see before splitting\n",
    "            - minGain    : minimum reduction in node impurity (classification or sd of node) required for splitting\n",
    "            - xrng       : range of the input space (see utils.dataRange)\n",
    "\n",
    "            Also for classification, you must set numClasses:\n",
    "            - numClasses : number of classes in response (it is assumed that the responses are integers 0,...,n-1)\n",
    "\n",
    "            The following are optional parameters with defaults:\n",
    "            - numClasses : see above (default: 0, for regression)\n",
    "            - numTests   : Number of potential split location and dimension pairs to test (defaul: 10)\n",
    "            - maxDepth   : Maximum depth a tree is allowed to have. A tree stops growing branches that have depth = maxDepth (default: 30. NOTE THAT YOUR TREE WILL NOT GROW BEYOND 30 DEEP, SET maxDepth TO BE A VALUE GREATER THAN 30 IF YOU WANT LARGER TREES!!!)\n",
    "            - gamma      : Trees that are of age 1/gamma may be discarded. \n",
    "\n",
    "        Two parameters are optional: \n",
    "        - numTrees       : number of trees in forest (default: 100)\n",
    "        - ncores         : number of cores to use. (default: 0). Currently NOT IMPLEMENTED, but  if ncores > 0, a parallel implementation will be invoked for speed gains. Preferrably using multiple threads. SO, DON'T USE THIS YET!!! See the update function below.\n",
    "        \n",
    "        usage:\n",
    "\n",
    "        orf = ORF(param,numTrees=20)\n",
    "        \"\"\"\n",
    "        self.param = param\n",
    "        self.classify = 1 if 'numClasses' in param.keys() else 0\n",
    "        self.numTrees = numTrees\n",
    "        self.forest = [ORT(param) for _ in range(numTrees)]\n",
    "        self.ncores = ncores\n",
    "        self.gamma = 0.05\n",
    "        self.Xs = deque(maxlen=10)\n",
    "\n",
    "    def update(self,x,y):\n",
    "        \"\"\"\n",
    "        updates the random forest by updating each tree in the forest. As mentioned above, this is currently not implemented. Please replace 'pass' (below) by the appropriate implementation.\n",
    "        \"\"\"\n",
    "        self.Xs.append(x) # dataset to construct new tree when one is discarded\n",
    "        # self.Ys.append(y) # dataset to construct new tree when one is discarded\n",
    "\n",
    "        if self.ncores > 1:\n",
    "            # parallel updates\n",
    "            pass # FIXME\n",
    "        else:\n",
    "            # sequential updates\n",
    "            \n",
    "            for tree in self.forest:\n",
    "                tree.update(x,y) # update each t in ORTs\n",
    "            \n",
    "            # Temporal Knowledge Weighting\n",
    "            \n",
    "            ages = [tree.age for tree in self.forest]\n",
    "            idx = [i for i, v in enumerate(ages) if v > 1/self.gamma]\n",
    "            \n",
    "            k = 1 # increasing this increases RMSE\n",
    "            if len(idx) > k:\n",
    "                randomIdx = random.choices(idx, k=k) # choose a random tree among those older than 1/gamma\n",
    "                OOBErrors = [tree.OOBError for tree in self.forest]\n",
    "\n",
    "                r = np.random.uniform(0, 1)\n",
    "                for ridx in randomIdx:\n",
    "                    if OOBErrors[ridx] > r: # if a randomly chosen tree's OOBE is larger than some random r\n",
    "                        self.param['xrng'] = dataRange(self.Xs)\n",
    "                        self.forest[ridx] = ORT(self.param) # discart the tree and construct a new tree\n",
    "                        self.forest[ridx].update(x, y)\n",
    "                \n",
    "\n",
    "    def predict(self,x):\n",
    "        \"\"\"\n",
    "        returns prediction (a scalar) of ORF based on input (x) which is a list of input variables\n",
    "\n",
    "        usage: \n",
    "\n",
    "        x = [1,2,3]\n",
    "        orf.predict(x)\n",
    "        \"\"\"\n",
    "        preds = [tree.predict(x) for tree in self.forest]\n",
    "        if self.classify: # if classification\n",
    "            cls_counts = [0] * self.param['numClasses']\n",
    "            for p in preds:\n",
    "                cls_counts[p] += 1\n",
    "            return np.argmax(cls_counts)\n",
    "        else:\n",
    "            return np.sum(preds) / (len(preds)*1.0)\n",
    "\n",
    "    def predicts(self,X):\n",
    "        \"\"\"\n",
    "        returns predictions (a list) of ORF based on inputs (X) which is a list of list input variables\n",
    "\n",
    "        usage: \n",
    "\n",
    "        X = [ [1,2,3], [2,3,4], [3,4,5] ]\n",
    "        orf.predict(X)\n",
    "        \"\"\"\n",
    "        return [self.predict(x) for x in X]\n",
    "\n",
    "    def predStat(self,x,f):\n",
    "        \"\"\"\n",
    "        returns a statistic aka function (f) of the predictions of the trees in the forest given input x.\n",
    "\n",
    "        usage:\n",
    "\n",
    "        def mean(xs):\n",
    "            return sum(xs) / float(len(xs))\n",
    "\n",
    "        orf.predStat(x,f) # returns same thing as orf.predict(x). You would replace f by some other function (e.g. sd, quantile, etc.) to get more exotic statistics for predictions.\n",
    "        \"\"\"\n",
    "        return f([tree.predict(x) for tree in self.forest])\n",
    "\n",
    "    def meanTreeSize(self):\n",
    "        \"\"\"\n",
    "        returns mean tree size of trees in forest. usage:\n",
    "\n",
    "        orf.meanTreeSize()\n",
    "\n",
    "        Same idea for next 5 methods (for mean and std. dev.)\n",
    "        \"\"\"\n",
    "        return mean(list(map(lambda ort: ort.tree.size(), self.forest)))\n",
    "\n",
    "    def meanNumLeaves(self):\n",
    "        return mean(list(map(lambda ort: ort.tree.numLeaves(), self.forest)))\n",
    "\n",
    "    def meanMaxDepth(self):\n",
    "        return mean(list(map(lambda ort: ort.tree.maxDepth(), self.forest)))\n",
    "\n",
    "    def sdTreeSize(self):\n",
    "        return sd([ort.tree.size() for ort in self.forest])\n",
    "\n",
    "    def sdNumLEaves(self):\n",
    "        return sd([ort.tree.numLeaves() for ort in self.forest])\n",
    "\n",
    "    def sdMaxDepth(self):\n",
    "        return sd([ort.tree.maxDepth() for ort in self.forest])\n",
    "    \n",
    "    def confusion(self,xs,ys):\n",
    "        \"\"\"\n",
    "        creates a confusion matrix based on list of list of inputs xs, and list of responses (ys). Ideally, xs and ys are out-of-sample data.\n",
    "\n",
    "        usage:\n",
    "\n",
    "        orf.confusion(xs,ys)\n",
    "        \"\"\"\n",
    "        n = self.param['numClasses']\n",
    "        assert n > 1, \"Confusion matrices can only be obtained for classification data.\" \n",
    "        preds = self.predicts(xs)\n",
    "        conf = [[0] * n for _ in range(n)]\n",
    "        for (y,p) in zip(ys,preds):\n",
    "            conf[int(y)][p] += 1\n",
    "        return conf\n",
    "    \n",
    "    def printConfusion(self,conf):\n",
    "        \"\"\"\n",
    "        simply prints the confusion matrix from the previous confusion method.\n",
    "\n",
    "        usage:\n",
    "        conf = orf.confusion(xs,ys)\n",
    "        orf.printConfusion(conf)\n",
    "        \"\"\"\n",
    "        print(\"y/pred\" + \"\\t\" + \"\\t\".join(map(str,range(self.param['numClasses']))))\n",
    "        i = 0\n",
    "        for row in conf:\n",
    "            print(str(i) + \"\\t\" + \"\\t\".join(map(str,row)))\n",
    "            i += 1\n",
    "\n",
    "# Other functions:\n",
    "def mean(xs):\n",
    "    return np.sum(xs) / (len(xs)*1.0)\n",
    "\n",
    "def sd(xs): \n",
    "    n = len(xs) *1.0\n",
    "    mu = np.sum(xs) / n\n",
    "    return np.sqrt( sum(list(map(lambda x: (x-mu)*(x-mu),xs))) / (n-1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ORF Regression:\nf(0,0):          [-0.00664792] +/- [0.16688508]\nMean size:       169.24\nSD size:         58.851142467219525\nMean max depth:  23.31\nSD max depth:    5.84253819202344\nRMSE:            0.26336526039368235\n\n\n"
    }
   ],
   "source": [
    "# ORF Regression Test\n",
    "\n",
    "def f(x): # from Lui's code\n",
    "    result = np.zeros((x.shape[0], 1))\n",
    "    \"\"\"\n",
    "    outputs (n, 1) np.array\n",
    "    \"\"\"\n",
    "    for i, l in enumerate(x):\n",
    "        result[i] = np.sin(x[i, 0]) if x[i, 0] < x[i, 1] else np.cos(x[i, 1] + np.pi/2)\n",
    "    return result\n",
    "\n",
    "# repeat = 10\n",
    "# mses = []\n",
    "# for i in tqdm(range(repeat)):\n",
    "\n",
    "n = 1000\n",
    "X = np.random.randn(n,2)\n",
    "y = f(X)\n",
    "\n",
    "# param = {'minSamples': 10, 'minGain': 0, 'xrng': dataRange(X), 'maxDepth': 10}\n",
    "param = {'minSamples': 2, 'minGain': 0.1, 'xrng': dataRange(X), 'maxDepth': 30}\n",
    "\n",
    "xtest = np.random.randn(n,2)\n",
    "ytest = f(xtest)\n",
    "\n",
    "orf = ORF(param, numTrees=100)\n",
    "\n",
    "for i in range(n):\n",
    "    orf.update(X[i,:],y[i])\n",
    "\n",
    "preds = orf.predicts(xtest)\n",
    "\n",
    "mse = np.mean( list(map(lambda z: (z[0]-z[1])*(z[0]-z[1]) , zip(preds,ytest)) ))\n",
    "    # mses.append(mse)\n",
    "\n",
    "print( \"ORF Regression:\")\n",
    "print( \"f(0,0):          \" + str(orf.predict([0,0])) + \" +/- \" + str(orf.predStat([0,0],sd)))\n",
    "print( \"Mean size:       \" + str(orf.meanTreeSize()))\n",
    "print( \"SD size:         \" + str(orf.sdTreeSize()))\n",
    "print( \"Mean max depth:  \" + str(orf.meanMaxDepth()))\n",
    "print( \"SD max depth:    \" + str(orf.sdMaxDepth()))\n",
    "print( \"RMSE:            \" + str(np.mean(np.sqrt(mse)))) # 0.335(TKW with deque=10), 0.373(TKW with deque=50), 0.389 without TKW\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[array([0.05815808])]"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "x = np.random.randn(10, 4)\n",
    "y = []\n",
    "for i in range(len(x)):\n",
    "    y.append([x[i,0]+x[i,1], x[i,2]+x[i,3]])\n",
    "\n",
    "y2 = []\n",
    "for i in range(len(x)):\n",
    "    y2.append(np.sum(x[i,:]))\n",
    "\n",
    "param = {'minSamples': 2, 'minGain': 0.1, 'xrng': dataRange(X), 'maxDepth': 30}\n",
    "\n",
    "for i in range(len(x)):\n",
    "    orf.update(x[i,:],y2[i])\n",
    "\n",
    "xtest2 = np.random.rand(1,4)\n",
    "\n",
    "preds = orf.predicts(xtest2)\n",
    "\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n389.0\ny/pred\t0\t1\n0\t608\t3\n1\t44\t345\nORF Classify:\nMean max depth: 14.48\nMean Size: 82.16\nSD Size: 61.709113539877976\nAccuracy: 0.953\n\n\n"
    }
   ],
   "source": [
    "# ORF Classification test\n",
    "def f(x):\n",
    "    result = np.zeros((x.shape[0], 1))\n",
    "    for i, v in enumerate(x):\n",
    "        result[i] = int(v[0]*v[0] + v[1]*v[1] < 1)\n",
    "    return result\n",
    "\n",
    "n = 1000\n",
    "X = np.random.randn(n,2)\n",
    "y = f(X)\n",
    "param = {'minSamples': 2, 'minGain': .01, 'numClasses': 2, 'xrng': dataRange(X)}\n",
    "orf = ORF(param,numTrees=50)\n",
    "\n",
    "for i in range(n):\n",
    "    orf.update(X[i,:],int(y[i]))\n",
    "\n",
    "xtest = np.random.randn(n,2)\n",
    "ytest = f(xtest)\n",
    "preds = orf.predicts(xtest)\n",
    "conf = orf.confusion(xtest,ytest)\n",
    "print(\"\\n\")\n",
    "print( np.sum(ytest))\n",
    "orf.printConfusion(conf)\n",
    "\n",
    "acc = list(map(lambda z: z[0]==z[1] , zip(preds,ytest))) # About 0.93~0.98\n",
    "print( \"ORF Classify:\")\n",
    "print( \"Mean max depth: \" + str(orf.meanMaxDepth()))\n",
    "print( \"Mean Size: \" + str(orf.meanTreeSize()))\n",
    "print( \"SD Size: \" + str(orf.sdTreeSize()))\n",
    "print( \"Accuracy: \" + str(np.mean(acc)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}